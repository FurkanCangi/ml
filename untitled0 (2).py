# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rOUH9dbIebS8R-8ZIXU7Mz29mTk_TqkH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
import os

# TÃ¼m gÃ¶rsellerin indirilebileceÄŸi klasÃ¶rÃ¼ oluÅŸtur
os.makedirs("output/figures", exist_ok=True)
os.makedirs("output/tables", exist_ok=True)

# DosyayÄ± yÃ¼kle
df = pd.read_excel("self.xlsx")
print("Veri seti boyutu:", df.shape)
df.head()

# SayÄ±sal deÄŸiÅŸkenlerin genel Ã¶zet istatistikleri
desc_stats = df.describe(include='all')
desc_stats.to_csv("output/tables/descriptive_statistics.csv")

# Veri tÃ¼rlerini incele
print(df.dtypes)

# BoÅŸluk oranÄ± yÃ¼ksek sÃ¼tunlarÄ± belirle
missing_percent = df.isnull().mean().sort_values(ascending=False) * 100
missing_percent.to_csv("output/tables/missing_percentages.csv")

plt.figure(figsize=(12,6))
msno.matrix(df)
plt.title("Eksik Veri Matrisi")
plt.savefig("output/figures/missing_data_matrix.png", bbox_inches='tight')

plt.figure(figsize=(12,6))
msno.heatmap(df)
plt.title("Eksik Veri Korelasyon IsÄ± HaritasÄ±")
plt.savefig("output/figures/missing_data_heatmap.png", bbox_inches='tight')

categorical_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()
numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()

print("Kategorik DeÄŸiÅŸkenler:", categorical_cols)
print("SayÄ±sal DeÄŸiÅŸkenler:", numeric_cols)

"""for col in numeric_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[col].dropna(), kde=True, bins=30)
    plt.title(f'{col} DaÄŸÄ±lÄ±mÄ±')
    plt.xlabel(col)
    plt.ylabel("Frekans")
    plt.savefig(f"output/figures/hist_{col}.png", bbox_inches='tight')
    plt.close()

"""

# 1. Label mapping tanÄ±mÄ±
label_mappings = {
    "cinsiyet": {0: "KÄ±z", 1: "Erkek"},
    "premature": {0: "HayÄ±r", 1: "Evet"},
    "dogum_sekli": {0: "Normal", 1: "Sezaryen"},
    "dusuk_dogum_oykusu": {0: "Yok", 1: "Var"},
    "anne_egitim": {1: "Ä°lkokul", 2: "Ortaokul", 3: "Lise", 4: "Ãœniversite+"},
    "baba_egitim": {1: "Ä°lkokul", 2: "Ortaokul", 3: "Lise", 4: "Ãœniversite+"},
    "alerji": {0: "Yok", 1: "Var"},
    "kolik": {0: "Yok", 1: "Var"},
    "nobet_oykusu": {0: "Yok", 1: "Var"},
    "kronik_hastalik": {0: "Yok", 1: "Var"}
}

# 2. Etiketleri eÅŸleÅŸtir ve kategorik tipe Ã§evir
for col, mapping in label_mappings.items():
    if col in df.columns:
        df[col] = df[col].map(mapping)
        df[col] = df[col].astype("category")

# 3. GÃ¼ncel kategorik ve sayÄ±sal listeleri Ã§Ä±kar
categorical_cols = df.select_dtypes(include=["category", "object"]).columns.tolist()
numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()

print("âœ… Kategorik DeÄŸiÅŸkenler:", categorical_cols)
print("âœ… SayÄ±sal DeÄŸiÅŸkenler:", numeric_cols)

cutoff_values = {
    "intero_toplam": {
        "scale": "Ä°nterosepsiyon",
        "cutoff": 137,
        "direction": "positive",  # yÃ¼ksek iyi
        "risk_rule": "â‰¤",
        "risk_comment": "Atipik interosepsiyon"
    },
    "fizyolojik_regulasyon_toplam": {
        "scale": "Fizyolojik RegÃ¼lasyon",
        "cutoff": 78,
        "direction": "negative",  # yÃ¼ksek kÃ¶tÃ¼
        "risk_rule": "â‰¥",
        "risk_comment": "RegÃ¼lasyon sorunu riski"
    },
    "duyu_toplam": {
        "scale": "Duyusal RegÃ¼lasyon",
        "cutoff": 144,
        "direction": "negative",
        "risk_rule": "â‰¥",
        "risk_comment": "Duyusal regÃ¼lasyon riski"
    },
    "duygu_toplam": {
        "scale": "Duygusal RegÃ¼lasyon",
        "cutoff": 117,
        "direction": "negative",
        "risk_rule": "â‰¥",
        "risk_comment": "Duygusal regÃ¼lasyon riski"
    },
    "bilissel_toplam": {
        "scale": "BiliÅŸsel RegÃ¼lasyon",
        "cutoff": 114,
        "direction": "negative",
        "risk_rule": "â‰¥",
        "risk_comment": "BiliÅŸsel regÃ¼lasyon sorunu"
    },
    "yurut_toplam": {
        "scale": "YÃ¼rÃ¼tÃ¼cÃ¼ Ä°ÅŸlev",
        "cutoff": 114,
        "direction": "negative",
        "risk_rule": "â‰¥",
        "risk_comment": "YÃ¼rÃ¼tÃ¼cÃ¼ iÅŸlevde zayÄ±flÄ±k"
    },
    "alg_toplam": {
        "scale": "AlgÄ± & Praksi",
        "cutoff": 141,
        "direction": "negative",
        "risk_rule": "â‰¥",
        "risk_comment": "AlgÄ±/praksi sorunlarÄ±"
    },
    "adaptif_toplam": {
        "scale": "Adaptif DavranÄ±ÅŸ",
        "cutoff": 510,
        "direction": "positive",
        "risk_rule": "â‰¤",
        "risk_comment": "Adaptif beceri dÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼"
    }
}

from google.colab import files

import pandas as pd
import numpy as np
from google.colab import files

# TanÄ±mlayÄ±cÄ± istatistikler hesapla
desc_stats = pd.DataFrame({
    "Ortalama": df[numeric_cols].mean(),
    "Std Sapma": df[numeric_cols].std(),
    "Medyan": df[numeric_cols].median(),
    "Minimum": df[numeric_cols].min(),
    "Maksimum": df[numeric_cols].max()
}).round(3)

# Dosya yolu
output_path = "tanimlayici_istatistikler.csv"

# Kaydet
desc_stats.to_csv(output_path)

# GÃ¶zlemle
display(desc_stats.head())

# ğŸ’¾ Otomatik indirme tetikle
files.download(output_path)

import os
import seaborn as sns
import matplotlib.pyplot as plt
from zipfile import ZipFile
from google.colab import files

# Grafiklerin kaydedileceÄŸi klasÃ¶r
hist_folder = "histogram_kde_plots"
os.makedirs(hist_folder, exist_ok=True)

# Tema ayarÄ±
sns.set_style("whitegrid")

# Her sayÄ±sal deÄŸiÅŸken iÃ§in histogram + KDE Ã§iz
for col in numeric_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[col].dropna(), kde=True, bins=30, color="skyblue")
    plt.title(f"{col} - Histogram + KDE")
    plt.xlabel(col)
    plt.ylabel("Frekans / YoÄŸunluk")
    plt.tight_layout()
    plt.savefig(f"{hist_folder}/{col}.png")
    plt.close()

# ZIP dosyasÄ±na ekle
zip_name = "histogram_kde_grafikleri.zip"
with ZipFile(zip_name, 'w') as zipf:
    for file in os.listdir(hist_folder):
        zipf.write(os.path.join(hist_folder, file))

# Otomatik indir
files.download(zip_name)

import pandas as pd
from scipy.stats import shapiro
from google.colab import files

# 1. Anamnez deÄŸiÅŸkenlerini hariÃ§ tut
anamnez_deg = [
    "yas", "cinsiyet", "dogum_sekli", "premature", "dusuk_dogum_oykusu",
    "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk",
    "anne_yas_dogumda", "anne_egitim", "baba_egitim",
    "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# 2. SayÄ±sal deÄŸiÅŸkenlerden sadece Ã¶lÃ§ekleri al
numeric_cols_filtered = [col for col in numeric_cols if col not in anamnez_deg]

# 3. Normallik testi (Shapiro-Wilk) uygula
shapiro_results = []

for col in numeric_cols_filtered:
    try:
        data_clean = df[col].dropna()
        stat, p = shapiro(data_clean)
        shapiro_results.append({
            "Ã–lÃ§ek": col.replace("_", " ").title(),
            "Ä°statistik (W)": round(stat, 3),
            "df": len(data_clean),
            "p": "<0.001" if p < 0.001 else round(p, 3)
        })
    except Exception as e:
        shapiro_results.append({
            "Ã–lÃ§ek": col.replace("_", " ").title(),
            "Ä°statistik (W)": "â€“",
            "df": "â€“",
            "p": "â€“"
        })

# 4. DataFrame olarak dÃ¼zenle
df_teze = pd.DataFrame(shapiro_results)

# 5. CSV olarak kaydet ve indir
csv_path = "shapiro_teze_tablo_final.csv"
df_teze.to_csv(csv_path, index=False)
files.download(csv_path)

import os
import seaborn as sns
import matplotlib.pyplot as plt
from zipfile import ZipFile
from google.colab import files

# 1. Anamnez deÄŸiÅŸkenleri
anamnez_deg = [
    "yas", "cinsiyet", "dogum_sekli", "premature", "dusuk_dogum_oykusu",
    "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk",
    "anne_yas_dogumda", "anne_egitim", "baba_egitim",
    "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# 2. Grafik klasÃ¶rÃ¼ oluÅŸtur
folder = "anamnez_grafikleri"
os.makedirs(folder, exist_ok=True)

# 3. Grafik Ã¼ret
sns.set_style("whitegrid")

for col in anamnez_deg:
    if col in df.columns:
        plt.figure(figsize=(8, 4))
        sns.histplot(df[col].dropna(), kde=True, bins=30, color='steelblue')
        plt.title(f"{col.replace('_',' ').title()} - DaÄŸÄ±lÄ±m")
        plt.xlabel(col.replace('_',' ').title())
        plt.ylabel("Frekans")
        plt.tight_layout()
        plt.savefig(f"{folder}/{col}.png", dpi=300)
        plt.close()

# 4. Zipâ€™le
zip_name = "anamnez_dagilim_grafikleri.zip"
with ZipFile(zip_name, 'w') as zipf:
    for file in os.listdir(folder):
        zipf.write(os.path.join(folder, file))

# 5. Ä°ndir
files.download(zip_name)

import pandas as pd
from scipy.stats import shapiro
from google.colab import files

# 1. Anamnez deÄŸiÅŸkenleri
anamnez_deg = [
    "yas", "cinsiyet", "dogum_sekli", "premature", "dusuk_dogum_oykusu",
    "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk",
    "anne_yas_dogumda", "anne_egitim", "baba_egitim",
    "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# 2. Test ve tablo oluÅŸturma
anamnez_results = []

for col in anamnez_deg:
    try:
        data_clean = df[col].dropna()
        stat, p = shapiro(data_clean)
        anamnez_results.append({
            "DeÄŸiÅŸken": col.replace("_", " ").title(),
            "Ä°statistik (W)": round(stat, 3),
            "df": len(data_clean),
            "p": "<0.001" if p < 0.001 else round(p, 3)
        })
    except Exception as e:
        anamnez_results.append({
            "DeÄŸiÅŸken": col.replace("_", " ").title(),
            "Ä°statistik (W)": "â€“",
            "df": "â€“",
            "p": "â€“"
        })

# 3. DataFrame ve kaydetme
df_anamnez = pd.DataFrame(anamnez_results)
csv_path = "shapiro_anamnez_tablo.csv"
df_anamnez.to_csv(csv_path, index=False)

# 4. Ä°ndir
files.download(csv_path)

df = pd.read_csv("shapiro_teze_tablo_final.csv")
n_tested = df[df["Ä°statistik (W)"] != "â€“"].shape[0]
n_normal = df[df["p"] != "<0.001"].shape[0]
round(n_normal / n_tested * 100, 1)

import pandas as pd

# Ã–rnek: doÄŸru veri dosyasÄ±nÄ± yÃ¼kle
df = pd.read_excel("self.xlsx")  # ya da pd.read_csv(...) eÄŸer CSV ise

# Kontrol: "dogum_haftasi" sÃ¼tunu var mÄ±?
if "dogum_haftasi" in df.columns:
    df["dogum_haftasi_grup"] = pd.cut(
        df["dogum_haftasi"],
        bins=[0, 36, 38, 42, 50],
        labels=["Erken (<37)", "SÄ±nÄ±rda (37â€“38)", "ZamanÄ±nda (39â€“42)", "GecikmiÅŸ (>42)"]
    )
    print("âœ… 'dogum_haftasi_grup' baÅŸarÄ±yla oluÅŸturuldu.")
else:
    print("âŒ 'dogum_haftasi' sÃ¼tunu bulunamadÄ±. DoÄŸru veri dosyasÄ±nÄ± yÃ¼klediÄŸine emin ol.")

label_mappings = {
    "cinsiyet": {0: "Erkek", 1: "KÄ±z"},
    "premature": {0: "HayÄ±r", 1: "Evet"},
    "dogum_sekli": {0: "Normal", 1: "Sezaryen"},
    "dusuk_dogum_oykusu": {0: "Yok", 1: "Var"},
    # ...
}
for col, mapping in label_mappings.items():
    df[col] = df[col].map(mapping)

df["dogum_kilosu_kategorik"] = pd.cut(df["dogum_kilosu"],
    bins=[0, 2500, 4000, 6000],
    labels=["DÃ¼ÅŸÃ¼k (<2500g)", "Normal (2500â€“4000g)", "YÃ¼ksek (>4000g)"]
)

# 1. Eksik veri kontrolÃ¼
print("ğŸš¨ Eksik Veri SayÄ±sÄ±:")
print(df.isnull().sum()[df.isnull().sum() > 0])

# 2. TÃ¼r kontrolÃ¼
print("\nğŸ§¬ DeÄŸiÅŸken TÃ¼rleri:")
print(df.dtypes)

# 3. Kategorik etiket kontrolÃ¼ (Ã¶rnek: cinsiyet)
print("\nâœ… EtiketlenmiÅŸ mi? â€“ Cinsiyet, DoÄŸum Åekli vs.")
for col in ["cinsiyet", "dogum_sekli", "dusuk_dogum_oykusu"]:
    if col in df.columns:
        print(f"{col}: {df[col].unique()}")

# 4. MantÄ±ksal sapma (Ã¶rnek: yaÅŸ)
print("\nğŸ§¯ YaÅŸ sÄ±nÄ±rÄ± dÄ±ÅŸÄ±nda kalanlar:")
print(df[(df["yas"] < 0) | (df["yas"] > 100)])

# 5. Negatif sayÄ± var mÄ±? (Ã¶rn. kilo, haftalÄ±k doÄŸum)
print("\nâš ï¸ Negatif deÄŸerler iÃ§eren sÃ¼tunlar:")
for col in ["yas", "dogum_kilosu", "dogum_haftasi", "anne_yas_dogumda"]:
    if col in df.columns:
        print(f"{col}: Negatif sayÄ±lar: {sum(df[col] < 0)}")

# 6. Tekrarlayan satÄ±r var mÄ±?
print("\nğŸ“Œ Tekrarlayan SatÄ±r SayÄ±sÄ±:", df.duplicated().sum())

# 7. AyÄ±rt edici Ã¶rnek iÃ§in boxplot (manuel)
import seaborn as sns
import matplotlib.pyplot as plt
sns.boxplot(x=df["dogum_kilosu"])
plt.title("DoÄŸum Kilosu â€“ AykÄ±rÄ± DeÄŸer KontrolÃ¼")
plt.show()

import pandas as pd
import numpy as np
from scipy.stats import spearmanr
from google.colab import files

# 1. TÃ¼m sayÄ±sal deÄŸiÅŸkenleri buraya yaz
degiskenler = [
    'yas', 'dogum_haftasi', 'dogum_kilosu', 'kardes_sayisi', 'kacinci_cocuk', 'anne_yas_dogumda',
    'intero_farkindalik', 'intero_konum', 'intero_yogunluk', 'intero_dikkat', 'intero_ayirt', 'intero_toplam',
    'fizyolojik_regulasyon_toplam',
    'duyu_vestibuler_hiper', 'duyu_vestibuler_hipo', 'duyu_gorsel_hiper', 'duyu_gorsel_hipo',
    'duyu_isitsel_hiper', 'duyu_isitsel_hipo', 'duyu_taktil_hiper', 'duyu_taktil_hipo',
    'duyu_tatkoku_hiper', 'duyu_tatkoku_hipo', 'duyu_toplam',
    'duygu_hiperreaktivite', 'duygu_hiporeaktivite', 'duygu_baglanma', 'duygu_farkindalik', 'duygu_duygu_yonetimi', 'duygu_toplam',
    'bilissel_planlama', 'bilissel_esneklik', 'bilissel_baslatma', 'bilissel_oz_kontrol', 'bilissel_kendini_izleme', 'bilissel_toplam',
    'yurut_dikkat', 'yurut_calisan_bellek', 'yurut_problem_cozme', 'yurut_neden_sonuc', 'yurut_fikir_uretme', 'yurut_toplam',
    'alg_somatoduyusal', 'alg_vestibuler', 'alg_gorsel', 'alg_motor_planlama', 'alg_toplam',
    'adaptif_gunluk_yasam', 'adaptif_iletisim', 'adaptif_sosyal', 'adaptif_motor', 'adaptif_guvenlik', 'adaptif_toplam'
]

# 2. Veriyi oku
df = pd.read_excel("self.xlsx")
df_corr = df[degiskenler].copy()

# 3. Spearman korelasyon ve p-deÄŸerleri hesapla
r_vals = pd.DataFrame(index=degiskenler, columns=degiskenler)
p_vals = pd.DataFrame(index=degiskenler, columns=degiskenler)

for var1 in degiskenler:
    for var2 in degiskenler:
        if var1 == var2:
            r_vals.loc[var1, var2] = np.nan
            p_vals.loc[var1, var2] = np.nan
        else:
            r, p = spearmanr(df_corr[var1], df_corr[var2], nan_policy='omit')
            r_vals.loc[var1, var2] = r
            p_vals.loc[var1, var2] = p

# 4. BiÃ§imlendirilmiÅŸ Ã§Ä±ktÄ± (Ã¶rn. 0.421**, 0.278*)
tablo = pd.DataFrame(index=degiskenler, columns=degiskenler)

for row in degiskenler:
    for col in degiskenler:
        r = r_vals.loc[row, col]
        p = p_vals.loc[row, col]

        if pd.isna(r):
            tablo.loc[row, col] = "-"
        else:
            stars = "**" if p < 0.01 else "*" if p < 0.05 else ""
            tablo.loc[row, col] = f"{round(r, 3)}{stars}"

# 5. Kaydet + indir
csv_path = "tum_korelasyon_spearman.csv"
tablo.to_csv(csv_path)
files.download(csv_path)

import pandas as pd

# 1. Veriyi yÃ¼kle
df = pd.read_excel("self.xlsx")  # EÄŸer CSV ise: read_csv(...)

# 2. Cut-off kurallarÄ± (senin verdiÄŸin yapÄ±)
cutoff_rules = {
    "intero_toplam": {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# 3. SÄ±nÄ±flandÄ±rma fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:
        return "Riskli" if puan >= cutoff else "Tipik"
    else:
        return "Atipik" if puan <= cutoff else "Tipik"

# 4. Uygula
for degisken, rule in cutoff_rules.items():
    grup_adi = degisken.replace("_toplam", "") + "_grup"
    df[grup_adi] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# 5. SonuÃ§larÄ± kontrol et (Ã¶rnek gÃ¶sterim)
print(df[[degisken.replace("_toplam", "") + "_grup" for degisken in cutoff_rules]])

# Ã–lÃ§eklere gÃ¶re tipik/atipik grup sÄ±nÄ±flandÄ±rmasÄ±
cutoff_rules = {
    "intero_toplam": {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# Etiketleme fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:  # yÃ¼ksek kÃ¶tÃ¼
        return "Riskli" if puan >= cutoff else "Tipik"
    else:        # yÃ¼ksek iyi
        return "Atipik" if puan <= cutoff else "Tipik"

# Uygula
for degisken, rule in cutoff_rules.items():
    grup_adi = degisken.replace("_toplam", "") + "_grup"
    df[grup_adi] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# SonuÃ§: df'de yeni grup sÃ¼tunlarÄ± oluÅŸur (Ã¶rneÄŸin intero_grup, duygu_grup vs.)

from google.colab import files

# 1. Sadece grup sÃ¼tunlarÄ±nÄ± seÃ§ (Ã¶rn. intero_grup, duygu_grup...)
grup_sutunlari = [col for col in df.columns if col.endswith("_grup")]

# 2. Yeni DataFrame
df_gruplar = df[grup_sutunlari].copy()

# 3. Kaydet
csv_path = "olcek_grup_siniflari.csv"
df_gruplar.to_csv(csv_path, index=False)

# 4. Ä°ndir
files.download(csv_path)

import pandas as pd
from scipy.stats import mannwhitneyu
from google.colab import files

# 1. Veriyi yÃ¼kle
df = pd.read_excel("self.xlsx")

# 2. Cut-off kurallarÄ±
cutoff_rules = {
    "intero_toplam":  {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# 3. Etiketleme fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:
        return "Riskli" if puan >= cutoff else "Tipik"
    else:
        return "Atipik" if puan <= cutoff else "Tipik"

# 4. Grup etiketlerini oluÅŸtur
for degisken, rule in cutoff_rules.items():
    grup_adi = degisken.replace("_toplam", "") + "_grup"
    df[grup_adi] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# 5. Grup ve puan sÃ¼tunlarÄ± listesi
grup_deg = [col for col in df.columns if col.endswith("_grup")]
sayisal_deg = [col for col in df.columns if col.endswith("_toplam")]

# 6. Mannâ€“Whitney testlerini uygula
results = []

for grup_col in grup_deg:
    unique_gruplar = df[grup_col].dropna().unique()

    if len(unique_gruplar) != 2:
        continue  # Sadece iki gruplu olanlarÄ± test et

    g1_label, g2_label = unique_gruplar

    for hedef in sayisal_deg:
        g1 = df[df[grup_col] == g1_label][hedef].dropna()
        g2 = df[df[grup_col] == g2_label][hedef].dropna()

        if len(g1) > 0 and len(g2) > 0:
            stat, p = mannwhitneyu(g1, g2, alternative='two-sided')
            results.append({
                "Grup DeÄŸiÅŸkeni": grup_col,
                "Test Edilen Ã–lÃ§ek": hedef,
                "Grup 1": g1_label,
                "Grup 2": g2_label,
                "Grup1 Ort": round(g1.mean(), 2),
                "Grup2 Ort": round(g2.mean(), 2),
                "U DeÄŸeri": round(stat, 2),
                "p-deÄŸeri": round(p, 5),
                "AnlamlÄ± mÄ±?": "âœ…" if p < 0.05 else ""
            })

# 7. SonuÃ§larÄ± dÄ±ÅŸa aktar
df_mwu = pd.DataFrame(results)
df_mwu.to_csv("mann_whitney_sonuclari.csv", index=False)
files.download("mann_whitney_sonuclari.csv")

from scipy.stats import levene

# GruplarÄ± tanÄ±mla
grup1 = df[df["intero_grup"] == "Tipik"]["adaptif_toplam"].dropna()
grup2 = df[df["intero_grup"] == "Atipik"]["adaptif_toplam"].dropna()

# Levene testi
stat, p = levene(grup1, grup2)

# SonuÃ§
print(f"Levene Testi â€“ Varyans EÅŸitliÄŸi")
print(f"F = {stat:.3f}")
print(f"p-deÄŸeri = {p:.5f}")

if p < 0.05:
    print("â— Varyanslar eÅŸit deÄŸil (homojenlik varsayÄ±mÄ± saÄŸlanmÄ±yor)")
else:
    print("âœ… Varyanslar eÅŸit (homojenlik varsayÄ±mÄ± saÄŸlanÄ±yor)")

import pandas as pd
from scipy.stats import levene
from google.colab import files

# 1. Veriyi yÃ¼kle
df = pd.read_excel("self.xlsx")

# 2. Cut-off kurallarÄ± (gruplama iÃ§in)
cutoff_rules = {
    "intero_toplam": {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# 3. Etiketleme fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:
        return "Riskli" if puan >= cutoff else "Tipik"
    else:
        return "Atipik" if puan <= cutoff else "Tipik"

# 4. Grup sÃ¼tunlarÄ±nÄ± oluÅŸtur
for degisken, rule in cutoff_rules.items():
    grup_sutun = degisken.replace("_toplam", "") + "_grup"
    df[grup_sutun] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# 5. Grup ve sayÄ±sal deÄŸiÅŸken listeleri
grup_deg = [col for col in df.columns if col.endswith("_grup")]
sayisal_deg = [col for col in df.columns if col.endswith("_toplam")]

# 6. Levene testi sonuÃ§larÄ±nÄ± topla
levene_results = []

for grup_col in grup_deg:
    unique_vals = df[grup_col].dropna().unique()
    if len(unique_vals) != 2:
        continue  # sadece iki gruplu olanlarÄ± test et

    g1_label, g2_label = unique_vals

    for hedef in sayisal_deg:
        g1 = df[df[grup_col] == g1_label][hedef].dropna()
        g2 = df[df[grup_col] == g2_label][hedef].dropna()

        if len(g1) > 0 and len(g2) > 0:
            stat, p = levene(g1, g2)
            levene_results.append({
                "Grup DeÄŸiÅŸkeni": grup_col,
                "Grup 1": g1_label,
                "Grup 2": g2_label,
                "Test Edilen Ã–lÃ§ek": hedef,
                "F DeÄŸeri": round(stat, 3),
                "p-deÄŸeri": round(p, 5),
                "Varyanslar EÅŸit mi?": "âœ… Evet" if p >= 0.05 else "âŒ HayÄ±r"
            })

# 7. SonuÃ§larÄ± CSV olarak kaydet + indir
df_levene = pd.DataFrame(levene_results)
df_levene.to_csv("levene_testi_sonuclari.csv", index=False)
files.download("levene_testi_sonuclari.csv")

import pandas as pd
from scipy.stats import chi2_contingency, fisher_exact
from itertools import combinations
from google.colab import files

# 1. Veriyi yÃ¼kle
df = pd.read_excel("self.xlsx")

# 2. Kategorik deÄŸiÅŸken listesi
kategorik_deg = [
    "cinsiyet", "premature", "dogum_sekli", "dusuk_dogum_oykusu",
    "anne_egitim", "baba_egitim", "alerji", "kolik", "nobet_oykusu", "kronik_hastalik",
    "intero_grup", "fizyolojik_regulasyon_grup", "duyu_grup", "duygu_grup",
    "bilissel_grup", "yurut_grup", "alg_grup", "adaptif_grup"
]

# 3. SonuÃ§larÄ± toplayacaÄŸÄ±mÄ±z yer
results = []

# 4. Ä°kili kombinasyonlarÄ± test et
for col1, col2 in combinations(kategorik_deg, 2):
    try:
        # GeÃ§erli sÄ±nÄ±f sayÄ±sÄ± kontrolÃ¼
        if df[col1].nunique() < 2 or df[col2].nunique() < 2:
            results.append({
                "DeÄŸiÅŸken 1": col1,
                "DeÄŸiÅŸken 2": col2,
                "Test TÃ¼rÃ¼": "AtlandÄ±",
                "p-deÄŸeri": "â€“",
                "AÃ§Ä±klama": "Yetersiz kategori"
            })
            continue

        # Ã‡apraz tablo
        tablo = pd.crosstab(df[col1], df[col2])
        if tablo.empty:
            results.append({
                "DeÄŸiÅŸken 1": col1,
                "DeÄŸiÅŸken 2": col2,
                "Test TÃ¼rÃ¼": "AtlandÄ±",
                "p-deÄŸeri": "â€“",
                "AÃ§Ä±klama": "BoÅŸ tablo"
            })
            continue

        # Test seÃ§imi
        if tablo.shape == (2, 2):
            if (tablo.values < 5).any():
                stat, p = fisher_exact(tablo)
                test = "Fisherâ€™s Exact"
            else:
                stat, p, _, _ = chi2_contingency(tablo)
                test = "Chi-Square"
        else:
            stat, p, _, _ = chi2_contingency(tablo)
            test = "Chi-Square"

        results.append({
            "DeÄŸiÅŸken 1": col1,
            "DeÄŸiÅŸken 2": col2,
            "Test TÃ¼rÃ¼": test,
            "p-deÄŸeri": round(p, 5),
            "AÃ§Ä±klama": "âœ… AnlamlÄ±" if p < 0.05 else ""
        })

    except Exception as e:
        results.append({
            "DeÄŸiÅŸken 1": col1,
            "DeÄŸiÅŸken 2": col2,
            "Test TÃ¼rÃ¼": "HATA",
            "p-deÄŸeri": "â€“",
            "AÃ§Ä±klama": f"âš ï¸ {str(e)}"
        })

# 5. CSV'ye kaydet ve indir
df_final = pd.DataFrame(results)
df_final.to_csv("kategori_iliski_testleri_SAGLAM.csv", index=False)
files.download("kategori_iliski_testleri_SAGLAM.csv")

import pandas as pd
from scipy.stats import kruskal
from google.colab import files

# 1. Veriyi yÃ¼kle
df = pd.read_excel("self.xlsx")

# 2. Gerekli kategorik deÄŸiÅŸkeni Ã¼ret (Ã¶rn. dogum_kilosu_kategorik)
if "dogum_kilosu_kategorik" not in df.columns:
    df["dogum_kilosu_kategorik"] = pd.cut(df["dogum_kilosu"],
        bins=[0, 2500, 4000, 6000],
        labels=["DÃ¼ÅŸÃ¼k (<2500g)", "Normal (2500â€“4000g)", "YÃ¼ksek (>4000g)"]
    )

# 3. Grup (3+ kategori iÃ§eren) ve sayÄ±sal deÄŸiÅŸken listeleri
grup_deg = [
    "anne_egitim", "baba_egitim", "dogum_kilosu_kategorik"
]

sayisal_deg = [
    'intero_toplam', 'fizyolojik_regulasyon_toplam', 'duyu_toplam',
    'duygu_toplam', 'bilissel_toplam', 'yurut_toplam',
    'alg_toplam', 'adaptif_toplam'
]

# 4. Kruskalâ€“Wallis test sonuÃ§larÄ±nÄ± topla
kruskal_results = []

for grup_col in grup_deg:
    if df[grup_col].nunique() < 3:
        continue  # en az 3 grup olmalÄ±

    for hedef in sayisal_deg:
        try:
            groups = [g[hedef].dropna() for _, g in df.groupby(grup_col)]
            if all(len(g) > 0 for g in groups):
                stat, p = kruskal(*groups)
                kruskal_results.append({
                    "Grup DeÄŸiÅŸkeni": grup_col,
                    "Test Edilen Ã–lÃ§ek": hedef,
                    "Grup SayÄ±sÄ±": df[grup_col].nunique(),
                    "H Ä°statistiÄŸi": round(stat, 3),
                    "p-deÄŸeri": round(p, 5),
                    "AnlamlÄ± mÄ±?": "âœ…" if p < 0.05 else ""
                })
        except Exception as e:
            kruskal_results.append({
                "Grup DeÄŸiÅŸkeni": grup_col,
                "Test Edilen Ã–lÃ§ek": hedef,
                "Grup SayÄ±sÄ±": "â€“",
                "H Ä°statistiÄŸi": "â€“",
                "p-deÄŸeri": "â€“",
                "AnlamlÄ± mÄ±?": f"âš ï¸ {str(e)}"
            })

# 5. CSV Ã§Ä±ktÄ±sÄ± ve indirme
df_kruskal = pd.DataFrame(kruskal_results)
df_kruskal.to_csv("kruskal_wallis_sonuclari.csv", index=False)
files.download("kruskal_wallis_sonuclari.csv")

import pandas as pd
import numpy as np
from scipy.stats import norm
from google.colab import files

# 1. DosyayÄ± oku
df = pd.read_csv("mann_whitney_sonuclari.csv")

# 2. Etki bÃ¼yÃ¼klÃ¼ÄŸÃ¼ iÃ§in hesaplama fonksiyonu
def calculate_effect_size(U, n1, n2):
    n = n1 + n2
    mean_U = n1 * n2 / 2
    std_U = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)
    z = (U - mean_U) / std_U
    r = abs(z) / np.sqrt(n)
    return round(r, 3), round(z, 3)

# 3. Yeni sÃ¼tunlarÄ± hesapla
effect_sizes = []

for _, row in df.iterrows():
    try:
        # U, grup bÃ¼yÃ¼klÃ¼kleri
        u = float(row["U DeÄŸeri"])
        g1_mean = float(row["Grup1 Ort"])
        g2_mean = float(row["Grup2 Ort"])

        # Tahmini grup bÃ¼yÃ¼klÃ¼kleri (eÅŸit sayarsak yaklaÅŸÄ±k olur)
        n1 = n2 = 100  # BurayÄ± gerÃ§ek df ile dinamik yapabiliriz

        r, z = calculate_effect_size(u, n1, n2)

        yorum = (
            "KÃ¼Ã§Ã¼k" if r < 0.3 else
            "Orta" if r < 0.5 else
            "BÃ¼yÃ¼k"
        )

        effect_sizes.append({
            "Grup DeÄŸiÅŸkeni": row["Grup DeÄŸiÅŸkeni"],
            "Test Edilen Ã–lÃ§ek": row["Test Edilen Ã–lÃ§ek"],
            "U DeÄŸeri": u,
            "Cohen's r": r,
            "Z skoru": z,
            "Etki": yorum
        })

    except:
        continue

# 4. Kaydet ve indir
df_r = pd.DataFrame(effect_sizes)
df_r.to_csv("cohens_r_sonuclari.csv", index=False)
files.download("cohens_r_sonuclari.csv")

import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold

# 1. Veriyi yÃ¼kle
df = pd.read_excel("self.xlsx")

# 2. Hedef sÄ±nÄ±f: intero_toplam â†’ intero_grup â†’ intero_binary
df["intero_grup"] = df["intero_toplam"].apply(lambda x: "Atipik" if x <= 137 else "Tipik")
df["intero_binary"] = df["intero_grup"].map({"Tipik": 0, "Atipik": 1})

# 3. Ã–zellik seÃ§imi

# Alt faktÃ¶r + toplam puanlar
puansal_deg = [col for col in df.columns if any(prefix in col for prefix in [
    "intero_", "duyu_", "duygu_", "bilissel_", "yurut_", "alg_", "adaptif_"
]) and not col.endswith("_grup")]

# Anamnez deÄŸiÅŸkenleri
anamnez_deg = [
    "yas", "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk", "anne_yas_dogumda",
    "premature", "dogum_sekli", "dusuk_dogum_oykusu", "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# X ve y oluÅŸtur
X = df[puansal_deg + anamnez_deg].copy()
y = df["intero_binary"]

# 4. One-hot encode (kategorik anamnezler)
kategorikler = ["premature", "dogum_sekli", "dusuk_dogum_oykusu", "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"]
X = pd.get_dummies(X, columns=kategorikler, drop_first=True)

# 5. Train/Test split (stratified)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# 6. Stratified K-Fold hazÄ±rlÄ±ÄŸÄ±
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 7. Bilgi mesajlarÄ±
print("âœ… Ã–zellik sayÄ±sÄ±:", X.shape[1])
print("âœ… Train/Test boyutlarÄ±:", X_train.shape, X_test.shape)
print("âœ… SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\n", y.value_counts(normalize=True))

import pandas as pd

# 1. Veriyi yÃ¼kle (Ã¶rnek)
df = pd.read_excel("self.xlsx")

# 2. Cut-off kurallarÄ± (senin verdiÄŸin gibi)
cutoff_info = {
    "intero_toplam": {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# 3. Grup sÃ¼tunlarÄ±nÄ± oluÅŸtur (Tipik / Riskli/Atipik)
for var, rule in cutoff_info.items():
    if rule["hi_good"]:
        df[var + "_grup"] = df[var].apply(lambda x: "Atipik" if x <= rule["cut"] else "Tipik")
    else:
        df[var + "_grup"] = df[var].apply(lambda x: "Riskli" if x >= rule["cut"] else "Tipik")

# 4. Her biri iÃ§in oranlarÄ± yazdÄ±r
for var in cutoff_info:
    print(f"\nğŸ“Š {var} daÄŸÄ±lÄ±mÄ±:")
    print(df[var + "_grup"].value_counts(normalize=True).round(3) * 100)

import pandas as pd

# 1. Veriyi yÃ¼kle
df = pd.read_excel("self.xlsx")  # veya .csv ise pd.read_csv("...")

# 2. Cut-off kurallarÄ±
cutoff_info = {
    "intero_toplam":  {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# 3. Grup etiketleri: Tipik / Riskliâ€“Atipik
for col, rule in cutoff_info.items():
    cut = rule["cut"]
    if rule["hi_good"]:
        df[col + "_grup"] = df[col].apply(lambda x: "Atipik" if x <= cut else "Tipik")
    else:
        df[col + "_grup"] = df[col].apply(lambda x: "Riskli" if x >= cut else "Tipik")

# Riskli/Atipik olanlar 1, diÄŸerleri 0 olacak ÅŸekilde binary dÃ¶nÃ¼ÅŸÃ¼m
def grup_to_binary(val):
    return 1 if val in ["Riskli", "Atipik"] else 0

risk_flags = []
for col in cutoff_info.keys():
    binary_col = col + "_bin"
    df[binary_col] = df[col + "_grup"].map(grup_to_binary)
    risk_flags.append(binary_col)

# Ensemble hedef: en az 3 riskli varsa â†’ 1
df["ensemble_binary"] = df[risk_flags].sum(axis=1).apply(lambda x: 1 if x >= 3 else 0)

# X: Alt faktÃ¶rler + toplam puanlar + anamnez
alt_factors = [col for col in df.columns if "_" in col and col.endswith("_toplam") == False and col not in risk_flags and not col.endswith("_grup")]
toplamlar = list(cutoff_info.keys())
anamnez = [
    "yas","cinsiyet","premature","dogum_haftasi","dogum_kilosu","dogum_sekli",
    "dusuk_dogum_oykusu","kardes_sayisi","kacinci_cocuk","anne_yas_dogumda",
    "anne_egitim","baba_egitim","alerji","kolik","nobet_oykusu","kronik_hastalik"
]

X = df[alt_factors + toplamlar + anamnez].copy()
y = df["ensemble_binary"]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print("âœ… Train:", X_train.shape, "Test:", X_test.shape)
print("ğŸ“Š SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± (train):")
print(y_train.value_counts(normalize=True).round(3) * 100)

# 1. Cut-off bilgisi tekrar
cutoff_info = {
    "intero_toplam":  {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# 2. Multi-label hedefler oluÅŸturuluyor
for col, rule in cutoff_info.items():
    y_col = col.replace("_toplam", "_y")
    if rule["hi_good"]:
        df[y_col] = df[col].apply(lambda x: 1 if x <= rule["cut"] else 0)
    else:
        df[y_col] = df[col].apply(lambda x: 1 if x >= rule["cut"] else 0)

# Cut-off kurallarÄ±
cutoff_info = {
    "intero_toplam":  {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# Grup etiketi â†’ Tipik / Riskli / Atipik
for col, rule in cutoff_info.items():
    cut = rule["cut"]
    if rule["hi_good"]:
        df[col + "_grup"] = df[col].apply(lambda x: "Atipik" if x <= cut else "Tipik")
    else:
        df[col + "_grup"] = df[col].apply(lambda x: "Riskli" if x >= cut else "Tipik")

# Binary Ã§evirim (1 = riskli/atipik)
def grup_to_binary(val):
    return 1 if val in ["Riskli", "Atipik"] else 0

risk_flags = []
for col in cutoff_info.keys():
    binary_col = col + "_bin"
    df[binary_col] = df[col + "_grup"].map(grup_to_binary)
    risk_flags.append(binary_col)

# ğŸ¯ Ensemble hedef: en az 3 riskli/atipik varsa = 1
df["ensemble_binary"] = df[risk_flags].sum(axis=1).apply(lambda x: 1 if x >= 3 else 0)

# 1. X â†’ Alt faktÃ¶rler (intero hariÃ§) + anamnez (toplamlar yok!)
alt_factors = [
    col for col in df.columns
    if "_" in col
    and col.endswith("_toplam") == False
    and not col.startswith("intero_")
    and not col.endswith("_grup")
    and not col.endswith("_bin")
    and not col.endswith("_y")
]

anamnez = [
    "yas","cinsiyet","premature","dogum_haftasi","dogum_kilosu","dogum_sekli",
    "dusuk_dogum_oykusu","kardes_sayisi","kacinci_cocuk","anne_yas_dogumda",
    "anne_egitim","baba_egitim","alerji","kolik","nobet_oykusu","kronik_hastalik"
]

X = df[alt_factors + anamnez].copy()
y = df["ensemble_binary"]

# 2. Kategorikleri one-hot encode et
kategorik_kolonlar = X.select_dtypes(include=["object", "category"]).columns.tolist()
X = pd.get_dummies(X, columns=kategorik_kolonlar, drop_first=True)

# 3. Train/test split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print("âœ… Ã–zellik sayÄ±sÄ±:", X.shape[1])
print("âœ… Train shape:", X_train.shape)
print("ğŸ“Š SÄ±nÄ±f oranlarÄ±:\n", y.value_counts(normalize=True).round(3) * 100)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# 1. Veri yÃ¼kle
df = pd.read_excel("self.xlsx")

# 2. Hedef deÄŸiÅŸken (interosepsiyon: 1=atipik, 0=tipik)
df["intero_y"] = (df["intero_toplam"] <= 137).astype(int)
y = df["intero_y"]

# 3. Risk etiketleri (cut-off'lara gÃ¶re)
df["fizyolojik_y"] = (df["fizyolojik_regulasyon_toplam"] >= 78).astype(int)
df["duyusal_y"] = (df["duyu_toplam"] >= 144).astype(int)
df["duygu_y"] = (df["duygu_toplam"] >= 117).astype(int)
df["bilissel_y"] = (df["bilissel_toplam"] >= 114).astype(int)
df["yurut_y"] = (df["yurut_toplam"] >= 114).astype(int)
df["alg_y"] = (df["alg_toplam"] >= 141).astype(int)
df["adaptif_y"] = (df["adaptif_toplam"] <= 510).astype(int)

# 4. Alt faktÃ¶rleri Ã§ek (intero_ ile baÅŸlayanlar hariÃ§)
alt_faktors = [
    col for col in df.columns
    if "_" in col and col.endswith("_toplam") == False
    and not col.startswith("intero_")
    and not col.endswith("_grup")
    and not col.endswith("_y")
]

# 5. Feature set (alt faktÃ¶rler + risk etiketleri)
X = df[alt_faktors + [
    "fizyolojik_y", "duyusal_y", "duygu_y", "bilissel_y",
    "yurut_y", "alg_y", "adaptif_y"
]]

# 6. Train-test ayrÄ±mÄ± (stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

# 7. Model listesi
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, solver='liblinear'),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "SVM (RBF)": SVC(kernel='rbf', probability=True, random_state=42),
    "Naive Bayes": GaussianNB(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "MLP Classifier": MLPClassifier(max_iter=500, random_state=42)
}

# 8. Model karÅŸÄ±laÅŸtÄ±rmasÄ±
results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(X_test)[:, 1]
    elif hasattr(model, "decision_function"):
        probs = model.decision_function(X_test)
        probs = (probs - probs.min()) / (probs.max() - probs.min())
    else:
        probs = preds

    results.append({
        "Model": name,
        "Accuracy": round(accuracy_score(y_test, preds), 3),
        "Precision": round(precision_score(y_test, preds, zero_division=0), 3),
        "Recall": round(recall_score(y_test, preds), 3),
        "F1-Score": round(f1_score(y_test, preds), 3),
        "ROC-AUC": round(roc_auc_score(y_test, probs), 3)
    })

# 9. Tablo ve grafik
df_results = pd.DataFrame(results).sort_values("ROC-AUC", ascending=False)
display(df_results)

plt.figure(figsize=(10,6))
sns.barplot(data=df_results, y="Model", x="ROC-AUC", palette="cubehelix")
plt.title("Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Alt FaktÃ¶r + Risk Etiket)", fontsize=14)
plt.xlabel("ROC-AUC")
plt.ylabel("Model")
plt.tight_layout()
plt.show()

# 10. Tez Ã§Ä±ktÄ±sÄ±
df_results.to_csv("tez_model_sonuc_riskvealtfaktor.csv", index=False)

