# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rOUH9dbIebS8R-8ZIXU7Mz29mTk_TqkH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
import os

# Tüm görsellerin indirilebileceği klasörü oluştur
os.makedirs("output/figures", exist_ok=True)
os.makedirs("output/tables", exist_ok=True)

# Dosyayı yükle
df = pd.read_excel("self.xlsx")
print("Veri seti boyutu:", df.shape)
df.head()

# Sayısal değişkenlerin genel özet istatistikleri
desc_stats = df.describe(include='all')
desc_stats.to_csv("output/tables/descriptive_statistics.csv")

# Veri türlerini incele
print(df.dtypes)

# Boşluk oranı yüksek sütunları belirle
missing_percent = df.isnull().mean().sort_values(ascending=False) * 100
missing_percent.to_csv("output/tables/missing_percentages.csv")

plt.figure(figsize=(12,6))
msno.matrix(df)
plt.title("Eksik Veri Matrisi")
plt.savefig("output/figures/missing_data_matrix.png", bbox_inches='tight')

plt.figure(figsize=(12,6))
msno.heatmap(df)
plt.title("Eksik Veri Korelasyon Isı Haritası")
plt.savefig("output/figures/missing_data_heatmap.png", bbox_inches='tight')

categorical_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()
numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()

print("Kategorik Değişkenler:", categorical_cols)
print("Sayısal Değişkenler:", numeric_cols)

"""for col in numeric_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[col].dropna(), kde=True, bins=30)
    plt.title(f'{col} Dağılımı')
    plt.xlabel(col)
    plt.ylabel("Frekans")
    plt.savefig(f"output/figures/hist_{col}.png", bbox_inches='tight')
    plt.close()

"""

# 1. Label mapping tanımı
label_mappings = {
    "cinsiyet": {0: "Kız", 1: "Erkek"},
    "premature": {0: "Hayır", 1: "Evet"},
    "dogum_sekli": {0: "Normal", 1: "Sezaryen"},
    "dusuk_dogum_oykusu": {0: "Yok", 1: "Var"},
    "anne_egitim": {1: "İlkokul", 2: "Ortaokul", 3: "Lise", 4: "Üniversite+"},
    "baba_egitim": {1: "İlkokul", 2: "Ortaokul", 3: "Lise", 4: "Üniversite+"},
    "alerji": {0: "Yok", 1: "Var"},
    "kolik": {0: "Yok", 1: "Var"},
    "nobet_oykusu": {0: "Yok", 1: "Var"},
    "kronik_hastalik": {0: "Yok", 1: "Var"}
}

# 2. Etiketleri eşleştir ve kategorik tipe çevir
for col, mapping in label_mappings.items():
    if col in df.columns:
        df[col] = df[col].map(mapping)
        df[col] = df[col].astype("category")

# 3. Güncel kategorik ve sayısal listeleri çıkar
categorical_cols = df.select_dtypes(include=["category", "object"]).columns.tolist()
numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()

print("✅ Kategorik Değişkenler:", categorical_cols)
print("✅ Sayısal Değişkenler:", numeric_cols)

cutoff_values = {
    "intero_toplam": {
        "scale": "İnterosepsiyon",
        "cutoff": 137,
        "direction": "positive",  # yüksek iyi
        "risk_rule": "≤",
        "risk_comment": "Atipik interosepsiyon"
    },
    "fizyolojik_regulasyon_toplam": {
        "scale": "Fizyolojik Regülasyon",
        "cutoff": 78,
        "direction": "negative",  # yüksek kötü
        "risk_rule": "≥",
        "risk_comment": "Regülasyon sorunu riski"
    },
    "duyu_toplam": {
        "scale": "Duyusal Regülasyon",
        "cutoff": 144,
        "direction": "negative",
        "risk_rule": "≥",
        "risk_comment": "Duyusal regülasyon riski"
    },
    "duygu_toplam": {
        "scale": "Duygusal Regülasyon",
        "cutoff": 117,
        "direction": "negative",
        "risk_rule": "≥",
        "risk_comment": "Duygusal regülasyon riski"
    },
    "bilissel_toplam": {
        "scale": "Bilişsel Regülasyon",
        "cutoff": 114,
        "direction": "negative",
        "risk_rule": "≥",
        "risk_comment": "Bilişsel regülasyon sorunu"
    },
    "yurut_toplam": {
        "scale": "Yürütücü İşlev",
        "cutoff": 114,
        "direction": "negative",
        "risk_rule": "≥",
        "risk_comment": "Yürütücü işlevde zayıflık"
    },
    "alg_toplam": {
        "scale": "Algı & Praksi",
        "cutoff": 141,
        "direction": "negative",
        "risk_rule": "≥",
        "risk_comment": "Algı/praksi sorunları"
    },
    "adaptif_toplam": {
        "scale": "Adaptif Davranış",
        "cutoff": 510,
        "direction": "positive",
        "risk_rule": "≤",
        "risk_comment": "Adaptif beceri düşüklüğü"
    }
}

from google.colab import files

import pandas as pd
import numpy as np
from google.colab import files

# Tanımlayıcı istatistikler hesapla
desc_stats = pd.DataFrame({
    "Ortalama": df[numeric_cols].mean(),
    "Std Sapma": df[numeric_cols].std(),
    "Medyan": df[numeric_cols].median(),
    "Minimum": df[numeric_cols].min(),
    "Maksimum": df[numeric_cols].max()
}).round(3)

# Dosya yolu
output_path = "tanimlayici_istatistikler.csv"

# Kaydet
desc_stats.to_csv(output_path)

# Gözlemle
display(desc_stats.head())

# 💾 Otomatik indirme tetikle
files.download(output_path)

import os
import seaborn as sns
import matplotlib.pyplot as plt
from zipfile import ZipFile
from google.colab import files

# Grafiklerin kaydedileceği klasör
hist_folder = "histogram_kde_plots"
os.makedirs(hist_folder, exist_ok=True)

# Tema ayarı
sns.set_style("whitegrid")

# Her sayısal değişken için histogram + KDE çiz
for col in numeric_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[col].dropna(), kde=True, bins=30, color="skyblue")
    plt.title(f"{col} - Histogram + KDE")
    plt.xlabel(col)
    plt.ylabel("Frekans / Yoğunluk")
    plt.tight_layout()
    plt.savefig(f"{hist_folder}/{col}.png")
    plt.close()

# ZIP dosyasına ekle
zip_name = "histogram_kde_grafikleri.zip"
with ZipFile(zip_name, 'w') as zipf:
    for file in os.listdir(hist_folder):
        zipf.write(os.path.join(hist_folder, file))

# Otomatik indir
files.download(zip_name)

import pandas as pd
from scipy.stats import shapiro
from google.colab import files

# 1. Anamnez değişkenlerini hariç tut
anamnez_deg = [
    "yas", "cinsiyet", "dogum_sekli", "premature", "dusuk_dogum_oykusu",
    "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk",
    "anne_yas_dogumda", "anne_egitim", "baba_egitim",
    "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# 2. Sayısal değişkenlerden sadece ölçekleri al
numeric_cols_filtered = [col for col in numeric_cols if col not in anamnez_deg]

# 3. Normallik testi (Shapiro-Wilk) uygula
shapiro_results = []

for col in numeric_cols_filtered:
    try:
        data_clean = df[col].dropna()
        stat, p = shapiro(data_clean)
        shapiro_results.append({
            "Ölçek": col.replace("_", " ").title(),
            "İstatistik (W)": round(stat, 3),
            "df": len(data_clean),
            "p": "<0.001" if p < 0.001 else round(p, 3)
        })
    except Exception as e:
        shapiro_results.append({
            "Ölçek": col.replace("_", " ").title(),
            "İstatistik (W)": "–",
            "df": "–",
            "p": "–"
        })

# 4. DataFrame olarak düzenle
df_teze = pd.DataFrame(shapiro_results)

# 5. CSV olarak kaydet ve indir
csv_path = "shapiro_teze_tablo_final.csv"
df_teze.to_csv(csv_path, index=False)
files.download(csv_path)

import os
import seaborn as sns
import matplotlib.pyplot as plt
from zipfile import ZipFile
from google.colab import files

# 1. Anamnez değişkenleri
anamnez_deg = [
    "yas", "cinsiyet", "dogum_sekli", "premature", "dusuk_dogum_oykusu",
    "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk",
    "anne_yas_dogumda", "anne_egitim", "baba_egitim",
    "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# 2. Grafik klasörü oluştur
folder = "anamnez_grafikleri"
os.makedirs(folder, exist_ok=True)

# 3. Grafik üret
sns.set_style("whitegrid")

for col in anamnez_deg:
    if col in df.columns:
        plt.figure(figsize=(8, 4))
        sns.histplot(df[col].dropna(), kde=True, bins=30, color='steelblue')
        plt.title(f"{col.replace('_',' ').title()} - Dağılım")
        plt.xlabel(col.replace('_',' ').title())
        plt.ylabel("Frekans")
        plt.tight_layout()
        plt.savefig(f"{folder}/{col}.png", dpi=300)
        plt.close()

# 4. Zip’le
zip_name = "anamnez_dagilim_grafikleri.zip"
with ZipFile(zip_name, 'w') as zipf:
    for file in os.listdir(folder):
        zipf.write(os.path.join(folder, file))

# 5. İndir
files.download(zip_name)

import pandas as pd
from scipy.stats import shapiro
from google.colab import files

# 1. Anamnez değişkenleri
anamnez_deg = [
    "yas", "cinsiyet", "dogum_sekli", "premature", "dusuk_dogum_oykusu",
    "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk",
    "anne_yas_dogumda", "anne_egitim", "baba_egitim",
    "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# 2. Test ve tablo oluşturma
anamnez_results = []

for col in anamnez_deg:
    try:
        data_clean = df[col].dropna()
        stat, p = shapiro(data_clean)
        anamnez_results.append({
            "Değişken": col.replace("_", " ").title(),
            "İstatistik (W)": round(stat, 3),
            "df": len(data_clean),
            "p": "<0.001" if p < 0.001 else round(p, 3)
        })
    except Exception as e:
        anamnez_results.append({
            "Değişken": col.replace("_", " ").title(),
            "İstatistik (W)": "–",
            "df": "–",
            "p": "–"
        })

# 3. DataFrame ve kaydetme
df_anamnez = pd.DataFrame(anamnez_results)
csv_path = "shapiro_anamnez_tablo.csv"
df_anamnez.to_csv(csv_path, index=False)

# 4. İndir
files.download(csv_path)

df = pd.read_csv("shapiro_teze_tablo_final.csv")
n_tested = df[df["İstatistik (W)"] != "–"].shape[0]
n_normal = df[df["p"] != "<0.001"].shape[0]
round(n_normal / n_tested * 100, 1)

import pandas as pd

# Örnek: doğru veri dosyasını yükle
df = pd.read_excel("self.xlsx")  # ya da pd.read_csv(...) eğer CSV ise

# Kontrol: "dogum_haftasi" sütunu var mı?
if "dogum_haftasi" in df.columns:
    df["dogum_haftasi_grup"] = pd.cut(
        df["dogum_haftasi"],
        bins=[0, 36, 38, 42, 50],
        labels=["Erken (<37)", "Sınırda (37–38)", "Zamanında (39–42)", "Gecikmiş (>42)"]
    )
    print("✅ 'dogum_haftasi_grup' başarıyla oluşturuldu.")
else:
    print("❌ 'dogum_haftasi' sütunu bulunamadı. Doğru veri dosyasını yüklediğine emin ol.")

label_mappings = {
    "cinsiyet": {0: "Erkek", 1: "Kız"},
    "premature": {0: "Hayır", 1: "Evet"},
    "dogum_sekli": {0: "Normal", 1: "Sezaryen"},
    "dusuk_dogum_oykusu": {0: "Yok", 1: "Var"},
    # ...
}
for col, mapping in label_mappings.items():
    df[col] = df[col].map(mapping)

df["dogum_kilosu_kategorik"] = pd.cut(df["dogum_kilosu"],
    bins=[0, 2500, 4000, 6000],
    labels=["Düşük (<2500g)", "Normal (2500–4000g)", "Yüksek (>4000g)"]
)

# 1. Eksik veri kontrolü
print("🚨 Eksik Veri Sayısı:")
print(df.isnull().sum()[df.isnull().sum() > 0])

# 2. Tür kontrolü
print("\n🧬 Değişken Türleri:")
print(df.dtypes)

# 3. Kategorik etiket kontrolü (örnek: cinsiyet)
print("\n✅ Etiketlenmiş mi? – Cinsiyet, Doğum Şekli vs.")
for col in ["cinsiyet", "dogum_sekli", "dusuk_dogum_oykusu"]:
    if col in df.columns:
        print(f"{col}: {df[col].unique()}")

# 4. Mantıksal sapma (örnek: yaş)
print("\n🧯 Yaş sınırı dışında kalanlar:")
print(df[(df["yas"] < 0) | (df["yas"] > 100)])

# 5. Negatif sayı var mı? (örn. kilo, haftalık doğum)
print("\n⚠️ Negatif değerler içeren sütunlar:")
for col in ["yas", "dogum_kilosu", "dogum_haftasi", "anne_yas_dogumda"]:
    if col in df.columns:
        print(f"{col}: Negatif sayılar: {sum(df[col] < 0)}")

# 6. Tekrarlayan satır var mı?
print("\n📌 Tekrarlayan Satır Sayısı:", df.duplicated().sum())

# 7. Ayırt edici örnek için boxplot (manuel)
import seaborn as sns
import matplotlib.pyplot as plt
sns.boxplot(x=df["dogum_kilosu"])
plt.title("Doğum Kilosu – Aykırı Değer Kontrolü")
plt.show()

import pandas as pd
import numpy as np
from scipy.stats import spearmanr
from google.colab import files

# 1. Tüm sayısal değişkenleri buraya yaz
degiskenler = [
    'yas', 'dogum_haftasi', 'dogum_kilosu', 'kardes_sayisi', 'kacinci_cocuk', 'anne_yas_dogumda',
    'intero_farkindalik', 'intero_konum', 'intero_yogunluk', 'intero_dikkat', 'intero_ayirt', 'intero_toplam',
    'fizyolojik_regulasyon_toplam',
    'duyu_vestibuler_hiper', 'duyu_vestibuler_hipo', 'duyu_gorsel_hiper', 'duyu_gorsel_hipo',
    'duyu_isitsel_hiper', 'duyu_isitsel_hipo', 'duyu_taktil_hiper', 'duyu_taktil_hipo',
    'duyu_tatkoku_hiper', 'duyu_tatkoku_hipo', 'duyu_toplam',
    'duygu_hiperreaktivite', 'duygu_hiporeaktivite', 'duygu_baglanma', 'duygu_farkindalik', 'duygu_duygu_yonetimi', 'duygu_toplam',
    'bilissel_planlama', 'bilissel_esneklik', 'bilissel_baslatma', 'bilissel_oz_kontrol', 'bilissel_kendini_izleme', 'bilissel_toplam',
    'yurut_dikkat', 'yurut_calisan_bellek', 'yurut_problem_cozme', 'yurut_neden_sonuc', 'yurut_fikir_uretme', 'yurut_toplam',
    'alg_somatoduyusal', 'alg_vestibuler', 'alg_gorsel', 'alg_motor_planlama', 'alg_toplam',
    'adaptif_gunluk_yasam', 'adaptif_iletisim', 'adaptif_sosyal', 'adaptif_motor', 'adaptif_guvenlik', 'adaptif_toplam'
]

# 2. Veriyi oku
df = pd.read_excel("self.xlsx")
df_corr = df[degiskenler].copy()

# 3. Spearman korelasyon ve p-değerleri hesapla
r_vals = pd.DataFrame(index=degiskenler, columns=degiskenler)
p_vals = pd.DataFrame(index=degiskenler, columns=degiskenler)

for var1 in degiskenler:
    for var2 in degiskenler:
        if var1 == var2:
            r_vals.loc[var1, var2] = np.nan
            p_vals.loc[var1, var2] = np.nan
        else:
            r, p = spearmanr(df_corr[var1], df_corr[var2], nan_policy='omit')
            r_vals.loc[var1, var2] = r
            p_vals.loc[var1, var2] = p

# 4. Biçimlendirilmiş çıktı (örn. 0.421**, 0.278*)
tablo = pd.DataFrame(index=degiskenler, columns=degiskenler)

for row in degiskenler:
    for col in degiskenler:
        r = r_vals.loc[row, col]
        p = p_vals.loc[row, col]

        if pd.isna(r):
            tablo.loc[row, col] = "-"
        else:
            stars = "**" if p < 0.01 else "*" if p < 0.05 else ""
            tablo.loc[row, col] = f"{round(r, 3)}{stars}"

# 5. Kaydet + indir
csv_path = "tum_korelasyon_spearman.csv"
tablo.to_csv(csv_path)
files.download(csv_path)

import pandas as pd

# 1. Veriyi yükle
df = pd.read_excel("self.xlsx")  # Eğer CSV ise: read_csv(...)

# 2. Cut-off kuralları (senin verdiğin yapı)
cutoff_rules = {
    "intero_toplam": {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# 3. Sınıflandırma fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:
        return "Riskli" if puan >= cutoff else "Tipik"
    else:
        return "Atipik" if puan <= cutoff else "Tipik"

# 4. Uygula
for degisken, rule in cutoff_rules.items():
    grup_adi = degisken.replace("_toplam", "") + "_grup"
    df[grup_adi] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# 5. Sonuçları kontrol et (örnek gösterim)
print(df[[degisken.replace("_toplam", "") + "_grup" for degisken in cutoff_rules]])

# Ölçeklere göre tipik/atipik grup sınıflandırması
cutoff_rules = {
    "intero_toplam": {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# Etiketleme fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:  # yüksek kötü
        return "Riskli" if puan >= cutoff else "Tipik"
    else:        # yüksek iyi
        return "Atipik" if puan <= cutoff else "Tipik"

# Uygula
for degisken, rule in cutoff_rules.items():
    grup_adi = degisken.replace("_toplam", "") + "_grup"
    df[grup_adi] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# Sonuç: df'de yeni grup sütunları oluşur (örneğin intero_grup, duygu_grup vs.)

from google.colab import files

# 1. Sadece grup sütunlarını seç (örn. intero_grup, duygu_grup...)
grup_sutunlari = [col for col in df.columns if col.endswith("_grup")]

# 2. Yeni DataFrame
df_gruplar = df[grup_sutunlari].copy()

# 3. Kaydet
csv_path = "olcek_grup_siniflari.csv"
df_gruplar.to_csv(csv_path, index=False)

# 4. İndir
files.download(csv_path)

import pandas as pd
from scipy.stats import mannwhitneyu
from google.colab import files

# 1. Veriyi yükle
df = pd.read_excel("self.xlsx")

# 2. Cut-off kuralları
cutoff_rules = {
    "intero_toplam":  {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# 3. Etiketleme fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:
        return "Riskli" if puan >= cutoff else "Tipik"
    else:
        return "Atipik" if puan <= cutoff else "Tipik"

# 4. Grup etiketlerini oluştur
for degisken, rule in cutoff_rules.items():
    grup_adi = degisken.replace("_toplam", "") + "_grup"
    df[grup_adi] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# 5. Grup ve puan sütunları listesi
grup_deg = [col for col in df.columns if col.endswith("_grup")]
sayisal_deg = [col for col in df.columns if col.endswith("_toplam")]

# 6. Mann–Whitney testlerini uygula
results = []

for grup_col in grup_deg:
    unique_gruplar = df[grup_col].dropna().unique()

    if len(unique_gruplar) != 2:
        continue  # Sadece iki gruplu olanları test et

    g1_label, g2_label = unique_gruplar

    for hedef in sayisal_deg:
        g1 = df[df[grup_col] == g1_label][hedef].dropna()
        g2 = df[df[grup_col] == g2_label][hedef].dropna()

        if len(g1) > 0 and len(g2) > 0:
            stat, p = mannwhitneyu(g1, g2, alternative='two-sided')
            results.append({
                "Grup Değişkeni": grup_col,
                "Test Edilen Ölçek": hedef,
                "Grup 1": g1_label,
                "Grup 2": g2_label,
                "Grup1 Ort": round(g1.mean(), 2),
                "Grup2 Ort": round(g2.mean(), 2),
                "U Değeri": round(stat, 2),
                "p-değeri": round(p, 5),
                "Anlamlı mı?": "✅" if p < 0.05 else ""
            })

# 7. Sonuçları dışa aktar
df_mwu = pd.DataFrame(results)
df_mwu.to_csv("mann_whitney_sonuclari.csv", index=False)
files.download("mann_whitney_sonuclari.csv")

from scipy.stats import levene

# Grupları tanımla
grup1 = df[df["intero_grup"] == "Tipik"]["adaptif_toplam"].dropna()
grup2 = df[df["intero_grup"] == "Atipik"]["adaptif_toplam"].dropna()

# Levene testi
stat, p = levene(grup1, grup2)

# Sonuç
print(f"Levene Testi – Varyans Eşitliği")
print(f"F = {stat:.3f}")
print(f"p-değeri = {p:.5f}")

if p < 0.05:
    print("❗ Varyanslar eşit değil (homojenlik varsayımı sağlanmıyor)")
else:
    print("✅ Varyanslar eşit (homojenlik varsayımı sağlanıyor)")

import pandas as pd
from scipy.stats import levene
from google.colab import files

# 1. Veriyi yükle
df = pd.read_excel("self.xlsx")

# 2. Cut-off kuralları (gruplama için)
cutoff_rules = {
    "intero_toplam": {"cutoff": 137, "reverse": False},
    "fizyolojik_regulasyon_toplam": {"cutoff": 78, "reverse": True},
    "duyu_toplam": {"cutoff": 144, "reverse": True},
    "duygu_toplam": {"cutoff": 117, "reverse": True},
    "bilissel_toplam": {"cutoff": 114, "reverse": True},
    "yurut_toplam": {"cutoff": 114, "reverse": True},
    "alg_toplam": {"cutoff": 141, "reverse": True},
    "adaptif_toplam": {"cutoff": 510, "reverse": False}
}

# 3. Etiketleme fonksiyonu
def grup_etiketle(puan, cutoff, reverse):
    if pd.isna(puan):
        return "Bilinmiyor"
    if reverse:
        return "Riskli" if puan >= cutoff else "Tipik"
    else:
        return "Atipik" if puan <= cutoff else "Tipik"

# 4. Grup sütunlarını oluştur
for degisken, rule in cutoff_rules.items():
    grup_sutun = degisken.replace("_toplam", "") + "_grup"
    df[grup_sutun] = df[degisken].apply(lambda x: grup_etiketle(x, rule["cutoff"], rule["reverse"]))

# 5. Grup ve sayısal değişken listeleri
grup_deg = [col for col in df.columns if col.endswith("_grup")]
sayisal_deg = [col for col in df.columns if col.endswith("_toplam")]

# 6. Levene testi sonuçlarını topla
levene_results = []

for grup_col in grup_deg:
    unique_vals = df[grup_col].dropna().unique()
    if len(unique_vals) != 2:
        continue  # sadece iki gruplu olanları test et

    g1_label, g2_label = unique_vals

    for hedef in sayisal_deg:
        g1 = df[df[grup_col] == g1_label][hedef].dropna()
        g2 = df[df[grup_col] == g2_label][hedef].dropna()

        if len(g1) > 0 and len(g2) > 0:
            stat, p = levene(g1, g2)
            levene_results.append({
                "Grup Değişkeni": grup_col,
                "Grup 1": g1_label,
                "Grup 2": g2_label,
                "Test Edilen Ölçek": hedef,
                "F Değeri": round(stat, 3),
                "p-değeri": round(p, 5),
                "Varyanslar Eşit mi?": "✅ Evet" if p >= 0.05 else "❌ Hayır"
            })

# 7. Sonuçları CSV olarak kaydet + indir
df_levene = pd.DataFrame(levene_results)
df_levene.to_csv("levene_testi_sonuclari.csv", index=False)
files.download("levene_testi_sonuclari.csv")

import pandas as pd
from scipy.stats import chi2_contingency, fisher_exact
from itertools import combinations
from google.colab import files

# 1. Veriyi yükle
df = pd.read_excel("self.xlsx")

# 2. Kategorik değişken listesi
kategorik_deg = [
    "cinsiyet", "premature", "dogum_sekli", "dusuk_dogum_oykusu",
    "anne_egitim", "baba_egitim", "alerji", "kolik", "nobet_oykusu", "kronik_hastalik",
    "intero_grup", "fizyolojik_regulasyon_grup", "duyu_grup", "duygu_grup",
    "bilissel_grup", "yurut_grup", "alg_grup", "adaptif_grup"
]

# 3. Sonuçları toplayacağımız yer
results = []

# 4. İkili kombinasyonları test et
for col1, col2 in combinations(kategorik_deg, 2):
    try:
        # Geçerli sınıf sayısı kontrolü
        if df[col1].nunique() < 2 or df[col2].nunique() < 2:
            results.append({
                "Değişken 1": col1,
                "Değişken 2": col2,
                "Test Türü": "Atlandı",
                "p-değeri": "–",
                "Açıklama": "Yetersiz kategori"
            })
            continue

        # Çapraz tablo
        tablo = pd.crosstab(df[col1], df[col2])
        if tablo.empty:
            results.append({
                "Değişken 1": col1,
                "Değişken 2": col2,
                "Test Türü": "Atlandı",
                "p-değeri": "–",
                "Açıklama": "Boş tablo"
            })
            continue

        # Test seçimi
        if tablo.shape == (2, 2):
            if (tablo.values < 5).any():
                stat, p = fisher_exact(tablo)
                test = "Fisher’s Exact"
            else:
                stat, p, _, _ = chi2_contingency(tablo)
                test = "Chi-Square"
        else:
            stat, p, _, _ = chi2_contingency(tablo)
            test = "Chi-Square"

        results.append({
            "Değişken 1": col1,
            "Değişken 2": col2,
            "Test Türü": test,
            "p-değeri": round(p, 5),
            "Açıklama": "✅ Anlamlı" if p < 0.05 else ""
        })

    except Exception as e:
        results.append({
            "Değişken 1": col1,
            "Değişken 2": col2,
            "Test Türü": "HATA",
            "p-değeri": "–",
            "Açıklama": f"⚠️ {str(e)}"
        })

# 5. CSV'ye kaydet ve indir
df_final = pd.DataFrame(results)
df_final.to_csv("kategori_iliski_testleri_SAGLAM.csv", index=False)
files.download("kategori_iliski_testleri_SAGLAM.csv")

import pandas as pd
from scipy.stats import kruskal
from google.colab import files

# 1. Veriyi yükle
df = pd.read_excel("self.xlsx")

# 2. Gerekli kategorik değişkeni üret (örn. dogum_kilosu_kategorik)
if "dogum_kilosu_kategorik" not in df.columns:
    df["dogum_kilosu_kategorik"] = pd.cut(df["dogum_kilosu"],
        bins=[0, 2500, 4000, 6000],
        labels=["Düşük (<2500g)", "Normal (2500–4000g)", "Yüksek (>4000g)"]
    )

# 3. Grup (3+ kategori içeren) ve sayısal değişken listeleri
grup_deg = [
    "anne_egitim", "baba_egitim", "dogum_kilosu_kategorik"
]

sayisal_deg = [
    'intero_toplam', 'fizyolojik_regulasyon_toplam', 'duyu_toplam',
    'duygu_toplam', 'bilissel_toplam', 'yurut_toplam',
    'alg_toplam', 'adaptif_toplam'
]

# 4. Kruskal–Wallis test sonuçlarını topla
kruskal_results = []

for grup_col in grup_deg:
    if df[grup_col].nunique() < 3:
        continue  # en az 3 grup olmalı

    for hedef in sayisal_deg:
        try:
            groups = [g[hedef].dropna() for _, g in df.groupby(grup_col)]
            if all(len(g) > 0 for g in groups):
                stat, p = kruskal(*groups)
                kruskal_results.append({
                    "Grup Değişkeni": grup_col,
                    "Test Edilen Ölçek": hedef,
                    "Grup Sayısı": df[grup_col].nunique(),
                    "H İstatistiği": round(stat, 3),
                    "p-değeri": round(p, 5),
                    "Anlamlı mı?": "✅" if p < 0.05 else ""
                })
        except Exception as e:
            kruskal_results.append({
                "Grup Değişkeni": grup_col,
                "Test Edilen Ölçek": hedef,
                "Grup Sayısı": "–",
                "H İstatistiği": "–",
                "p-değeri": "–",
                "Anlamlı mı?": f"⚠️ {str(e)}"
            })

# 5. CSV çıktısı ve indirme
df_kruskal = pd.DataFrame(kruskal_results)
df_kruskal.to_csv("kruskal_wallis_sonuclari.csv", index=False)
files.download("kruskal_wallis_sonuclari.csv")

import pandas as pd
import numpy as np
from scipy.stats import norm
from google.colab import files

# 1. Dosyayı oku
df = pd.read_csv("mann_whitney_sonuclari.csv")

# 2. Etki büyüklüğü için hesaplama fonksiyonu
def calculate_effect_size(U, n1, n2):
    n = n1 + n2
    mean_U = n1 * n2 / 2
    std_U = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)
    z = (U - mean_U) / std_U
    r = abs(z) / np.sqrt(n)
    return round(r, 3), round(z, 3)

# 3. Yeni sütunları hesapla
effect_sizes = []

for _, row in df.iterrows():
    try:
        # U, grup büyüklükleri
        u = float(row["U Değeri"])
        g1_mean = float(row["Grup1 Ort"])
        g2_mean = float(row["Grup2 Ort"])

        # Tahmini grup büyüklükleri (eşit sayarsak yaklaşık olur)
        n1 = n2 = 100  # Burayı gerçek df ile dinamik yapabiliriz

        r, z = calculate_effect_size(u, n1, n2)

        yorum = (
            "Küçük" if r < 0.3 else
            "Orta" if r < 0.5 else
            "Büyük"
        )

        effect_sizes.append({
            "Grup Değişkeni": row["Grup Değişkeni"],
            "Test Edilen Ölçek": row["Test Edilen Ölçek"],
            "U Değeri": u,
            "Cohen's r": r,
            "Z skoru": z,
            "Etki": yorum
        })

    except:
        continue

# 4. Kaydet ve indir
df_r = pd.DataFrame(effect_sizes)
df_r.to_csv("cohens_r_sonuclari.csv", index=False)
files.download("cohens_r_sonuclari.csv")

import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold

# 1. Veriyi yükle
df = pd.read_excel("self.xlsx")

# 2. Hedef sınıf: intero_toplam → intero_grup → intero_binary
df["intero_grup"] = df["intero_toplam"].apply(lambda x: "Atipik" if x <= 137 else "Tipik")
df["intero_binary"] = df["intero_grup"].map({"Tipik": 0, "Atipik": 1})

# 3. Özellik seçimi

# Alt faktör + toplam puanlar
puansal_deg = [col for col in df.columns if any(prefix in col for prefix in [
    "intero_", "duyu_", "duygu_", "bilissel_", "yurut_", "alg_", "adaptif_"
]) and not col.endswith("_grup")]

# Anamnez değişkenleri
anamnez_deg = [
    "yas", "dogum_haftasi", "dogum_kilosu", "kardes_sayisi", "kacinci_cocuk", "anne_yas_dogumda",
    "premature", "dogum_sekli", "dusuk_dogum_oykusu", "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"
]

# X ve y oluştur
X = df[puansal_deg + anamnez_deg].copy()
y = df["intero_binary"]

# 4. One-hot encode (kategorik anamnezler)
kategorikler = ["premature", "dogum_sekli", "dusuk_dogum_oykusu", "alerji", "kolik", "nobet_oykusu", "kronik_hastalik"]
X = pd.get_dummies(X, columns=kategorikler, drop_first=True)

# 5. Train/Test split (stratified)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# 6. Stratified K-Fold hazırlığı
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 7. Bilgi mesajları
print("✅ Özellik sayısı:", X.shape[1])
print("✅ Train/Test boyutları:", X_train.shape, X_test.shape)
print("✅ Sınıf dağılımı:\n", y.value_counts(normalize=True))

import pandas as pd

# 1. Veriyi yükle (örnek)
df = pd.read_excel("self.xlsx")

# 2. Cut-off kuralları (senin verdiğin gibi)
cutoff_info = {
    "intero_toplam": {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# 3. Grup sütunlarını oluştur (Tipik / Riskli/Atipik)
for var, rule in cutoff_info.items():
    if rule["hi_good"]:
        df[var + "_grup"] = df[var].apply(lambda x: "Atipik" if x <= rule["cut"] else "Tipik")
    else:
        df[var + "_grup"] = df[var].apply(lambda x: "Riskli" if x >= rule["cut"] else "Tipik")

# 4. Her biri için oranları yazdır
for var in cutoff_info:
    print(f"\n📊 {var} dağılımı:")
    print(df[var + "_grup"].value_counts(normalize=True).round(3) * 100)

import pandas as pd

# 1. Veriyi yükle
df = pd.read_excel("self.xlsx")  # veya .csv ise pd.read_csv("...")

# 2. Cut-off kuralları
cutoff_info = {
    "intero_toplam":  {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# 3. Grup etiketleri: Tipik / Riskli–Atipik
for col, rule in cutoff_info.items():
    cut = rule["cut"]
    if rule["hi_good"]:
        df[col + "_grup"] = df[col].apply(lambda x: "Atipik" if x <= cut else "Tipik")
    else:
        df[col + "_grup"] = df[col].apply(lambda x: "Riskli" if x >= cut else "Tipik")

# Riskli/Atipik olanlar 1, diğerleri 0 olacak şekilde binary dönüşüm
def grup_to_binary(val):
    return 1 if val in ["Riskli", "Atipik"] else 0

risk_flags = []
for col in cutoff_info.keys():
    binary_col = col + "_bin"
    df[binary_col] = df[col + "_grup"].map(grup_to_binary)
    risk_flags.append(binary_col)

# Ensemble hedef: en az 3 riskli varsa → 1
df["ensemble_binary"] = df[risk_flags].sum(axis=1).apply(lambda x: 1 if x >= 3 else 0)

# X: Alt faktörler + toplam puanlar + anamnez
alt_factors = [col for col in df.columns if "_" in col and col.endswith("_toplam") == False and col not in risk_flags and not col.endswith("_grup")]
toplamlar = list(cutoff_info.keys())
anamnez = [
    "yas","cinsiyet","premature","dogum_haftasi","dogum_kilosu","dogum_sekli",
    "dusuk_dogum_oykusu","kardes_sayisi","kacinci_cocuk","anne_yas_dogumda",
    "anne_egitim","baba_egitim","alerji","kolik","nobet_oykusu","kronik_hastalik"
]

X = df[alt_factors + toplamlar + anamnez].copy()
y = df["ensemble_binary"]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print("✅ Train:", X_train.shape, "Test:", X_test.shape)
print("📊 Sınıf dağılımı (train):")
print(y_train.value_counts(normalize=True).round(3) * 100)

# 1. Cut-off bilgisi tekrar
cutoff_info = {
    "intero_toplam":  {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# 2. Multi-label hedefler oluşturuluyor
for col, rule in cutoff_info.items():
    y_col = col.replace("_toplam", "_y")
    if rule["hi_good"]:
        df[y_col] = df[col].apply(lambda x: 1 if x <= rule["cut"] else 0)
    else:
        df[y_col] = df[col].apply(lambda x: 1 if x >= rule["cut"] else 0)

# Cut-off kuralları
cutoff_info = {
    "intero_toplam":  {"cut": 137, "hi_good": True},
    "fizyolojik_regulasyon_toplam": {"cut": 78, "hi_good": False},
    "duyu_toplam": {"cut": 144, "hi_good": False},
    "duygu_toplam": {"cut": 117, "hi_good": False},
    "bilissel_toplam": {"cut": 114, "hi_good": False},
    "yurut_toplam": {"cut": 114, "hi_good": False},
    "alg_toplam": {"cut": 141, "hi_good": False},
    "adaptif_toplam": {"cut": 510, "hi_good": True}
}

# Grup etiketi → Tipik / Riskli / Atipik
for col, rule in cutoff_info.items():
    cut = rule["cut"]
    if rule["hi_good"]:
        df[col + "_grup"] = df[col].apply(lambda x: "Atipik" if x <= cut else "Tipik")
    else:
        df[col + "_grup"] = df[col].apply(lambda x: "Riskli" if x >= cut else "Tipik")

# Binary çevirim (1 = riskli/atipik)
def grup_to_binary(val):
    return 1 if val in ["Riskli", "Atipik"] else 0

risk_flags = []
for col in cutoff_info.keys():
    binary_col = col + "_bin"
    df[binary_col] = df[col + "_grup"].map(grup_to_binary)
    risk_flags.append(binary_col)

# 🎯 Ensemble hedef: en az 3 riskli/atipik varsa = 1
df["ensemble_binary"] = df[risk_flags].sum(axis=1).apply(lambda x: 1 if x >= 3 else 0)

# 1. X → Alt faktörler (intero hariç) + anamnez (toplamlar yok!)
alt_factors = [
    col for col in df.columns
    if "_" in col
    and col.endswith("_toplam") == False
    and not col.startswith("intero_")
    and not col.endswith("_grup")
    and not col.endswith("_bin")
    and not col.endswith("_y")
]

anamnez = [
    "yas","cinsiyet","premature","dogum_haftasi","dogum_kilosu","dogum_sekli",
    "dusuk_dogum_oykusu","kardes_sayisi","kacinci_cocuk","anne_yas_dogumda",
    "anne_egitim","baba_egitim","alerji","kolik","nobet_oykusu","kronik_hastalik"
]

X = df[alt_factors + anamnez].copy()
y = df["ensemble_binary"]

# 2. Kategorikleri one-hot encode et
kategorik_kolonlar = X.select_dtypes(include=["object", "category"]).columns.tolist()
X = pd.get_dummies(X, columns=kategorik_kolonlar, drop_first=True)

# 3. Train/test split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print("✅ Özellik sayısı:", X.shape[1])
print("✅ Train shape:", X_train.shape)
print("📊 Sınıf oranları:\n", y.value_counts(normalize=True).round(3) * 100)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# 1. Veri yükle
df = pd.read_excel("self.xlsx")

# 2. Hedef değişken (interosepsiyon: 1=atipik, 0=tipik)
df["intero_y"] = (df["intero_toplam"] <= 137).astype(int)
y = df["intero_y"]

# 3. Risk etiketleri (cut-off'lara göre)
df["fizyolojik_y"] = (df["fizyolojik_regulasyon_toplam"] >= 78).astype(int)
df["duyusal_y"] = (df["duyu_toplam"] >= 144).astype(int)
df["duygu_y"] = (df["duygu_toplam"] >= 117).astype(int)
df["bilissel_y"] = (df["bilissel_toplam"] >= 114).astype(int)
df["yurut_y"] = (df["yurut_toplam"] >= 114).astype(int)
df["alg_y"] = (df["alg_toplam"] >= 141).astype(int)
df["adaptif_y"] = (df["adaptif_toplam"] <= 510).astype(int)

# 4. Alt faktörleri çek (intero_ ile başlayanlar hariç)
alt_faktors = [
    col for col in df.columns
    if "_" in col and col.endswith("_toplam") == False
    and not col.startswith("intero_")
    and not col.endswith("_grup")
    and not col.endswith("_y")
]

# 5. Feature set (alt faktörler + risk etiketleri)
X = df[alt_faktors + [
    "fizyolojik_y", "duyusal_y", "duygu_y", "bilissel_y",
    "yurut_y", "alg_y", "adaptif_y"
]]

# 6. Train-test ayrımı (stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

# 7. Model listesi
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, solver='liblinear'),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42),
    "SVM (RBF)": SVC(kernel='rbf', probability=True, random_state=42),
    "Naive Bayes": GaussianNB(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "MLP Classifier": MLPClassifier(max_iter=500, random_state=42)
}

# 8. Model karşılaştırması
results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(X_test)[:, 1]
    elif hasattr(model, "decision_function"):
        probs = model.decision_function(X_test)
        probs = (probs - probs.min()) / (probs.max() - probs.min())
    else:
        probs = preds

    results.append({
        "Model": name,
        "Accuracy": round(accuracy_score(y_test, preds), 3),
        "Precision": round(precision_score(y_test, preds, zero_division=0), 3),
        "Recall": round(recall_score(y_test, preds), 3),
        "F1-Score": round(f1_score(y_test, preds), 3),
        "ROC-AUC": round(roc_auc_score(y_test, probs), 3)
    })

# 9. Tablo ve grafik
df_results = pd.DataFrame(results).sort_values("ROC-AUC", ascending=False)
display(df_results)

plt.figure(figsize=(10,6))
sns.barplot(data=df_results, y="Model", x="ROC-AUC", palette="cubehelix")
plt.title("Model Performans Karşılaştırması (Alt Faktör + Risk Etiket)", fontsize=14)
plt.xlabel("ROC-AUC")
plt.ylabel("Model")
plt.tight_layout()
plt.show()

# 10. Tez çıktısı
df_results.to_csv("tez_model_sonuc_riskvealtfaktor.csv", index=False)

